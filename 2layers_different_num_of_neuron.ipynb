{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc17a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import bisect\n",
    "import numpy as np\n",
    "torch.manual_seed(1)\n",
    "err_all=[]\n",
    "num_list=[10,20,50,100]\n",
    "for i in range(len(num_list)):\n",
    "    N=num_list(i)\n",
    "    M=0.1*N*N\n",
    "    print(N)\n",
    "    class PINN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.model1 = nn.Sequential(\n",
    "                nn.Linear(2, N),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(N, M),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(M, 2)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            output = self.model1(x)\n",
    "            return output\n",
    "\n",
    "\n",
    "    class MSE0b(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, x, y):\n",
    "            output = torch.sum((x - y) ** 2)/len(x)\n",
    "            return output\n",
    "\n",
    "\n",
    "    class MSEf(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, x):\n",
    "            output = torch.sum(x ** 2)/len(x)\n",
    "            return output\n",
    "\n",
    "\n",
    "    # 模型初始化\n",
    "    pinn = PINN().cuda()\n",
    "    optimizer = torch.optim.LBFGS(pinn.parameters(), lr=0.2)\n",
    "    init_loss = MSE0b().cuda()\n",
    "    boundary_loss = MSE0b().cuda()\n",
    "    internal_loss = MSEf().cuda()\n",
    "    \n",
    "        # 初值训练点\n",
    "    N0 = 50\n",
    "    init_data = (torch.rand(N0, 2) - 0.5) * 10\n",
    "    init_data[:, 0:1] = torch.zeros((N0, 1))\n",
    "    init_data = init_data.cuda()\n",
    "    # init_data.requires_grad_()\n",
    "\n",
    "    init_target = torch.zeros((N0, 2))\n",
    "    init_target[:, 0:1] = 2 / torch.cosh(init_data[:, 1:2])\n",
    "    init_target = init_target.cuda()\n",
    "\n",
    "    # 边界训练点\n",
    "    Nb = 50\n",
    "    sample_time = torch.rand((Nb, 1))*torch.pi/2\n",
    "    bd1_data = torch.full((Nb, 2), 5.)\n",
    "    bd1_data[:, 0:1] = sample_time\n",
    "    bd2_data = torch.full((Nb, 2), -5.)\n",
    "    bd2_data[:, 0:1] = sample_time\n",
    "    bd1_data = bd1_data.cuda()\n",
    "    bd2_data = bd2_data.cuda()\n",
    "    # bd1_data.requires_grad_()\n",
    "    # bd2_data.requires_grad_()\n",
    "\n",
    "    # 内部训练点\n",
    "    Nf = 20000\n",
    "    sample_x = (torch.rand(Nf, 1) - 0.5) * 10\n",
    "    sample_time2 = torch.rand((Nf, 1))*torch.pi/2\n",
    "    internal_data = torch.zeros((Nf, 2))\n",
    "    internal_data[:, 0:1] = sample_time2\n",
    "    internal_data[:, 1:2] = sample_x\n",
    "    internal_data = internal_data.cuda()\n",
    "    # internal_data.requires_grad_()\n",
    "\n",
    "    # 求导梯度\n",
    "    bd_u_grad_out = torch.Tensor([[1, 0]*Nb]).reshape((-1, 2)).cuda()\n",
    "    bd_v_grad_out = torch.Tensor([[0, 1]*Nb]).reshape((-1, 2)).cuda()\n",
    "\n",
    "    internal_u_grad_out = torch.Tensor([[1, 0]*Nf]).reshape((-1, 2)).cuda()\n",
    "    internal_v_grad_out = torch.Tensor([[0, 1]*Nf]).reshape((-1, 2)).cuda()\n",
    "    \n",
    "    pinn.train()\n",
    "    def closure():\n",
    "        # 初值误差\n",
    "        init_data_ = init_data.clone()\n",
    "        init_data_.requires_grad_()\n",
    "        init_y = pinn(init_data_)\n",
    "        mse0 = init_loss(init_y, init_target)\n",
    "\n",
    "        # 边值误差\n",
    "        bd1_data_ = bd1_data.clone()\n",
    "        bd1_data_.requires_grad_()\n",
    "        bd2_data_ = bd2_data.clone()\n",
    "        bd2_data_.requires_grad_()\n",
    "        bd1_y = pinn(bd1_data_)\n",
    "        bd2_y = pinn(bd2_data_)\n",
    "\n",
    "        bd1_dudx = torch.autograd.grad(outputs=bd1_y, inputs=bd1_data_, grad_outputs=bd_u_grad_out, create_graph=True)[0][:, 1:2]\n",
    "        bd1_dvdx = torch.autograd.grad(outputs=bd1_y, inputs=bd1_data_, grad_outputs=bd_v_grad_out, create_graph=True)[0][:, 1:2]\n",
    "\n",
    "        bd2_dudx = torch.autograd.grad(outputs=bd2_y, inputs=bd2_data_, grad_outputs=bd_u_grad_out, create_graph=True)[0][:, 1:2]\n",
    "        bd2_dvdx = torch.autograd.grad(outputs=bd2_y, inputs=bd2_data_, grad_outputs=bd_v_grad_out, create_graph=True)[0][:, 1:2]\n",
    "\n",
    "        mseb = boundary_loss(bd1_dudx, bd2_dudx) + boundary_loss(bd1_dvdx, bd2_dvdx)\n",
    "\n",
    "        # 内点误差\n",
    "        internal_data_ = internal_data.clone()\n",
    "        internal_data_.requires_grad_()\n",
    "        internal_y = pinn(internal_data_)\n",
    "\n",
    "        internal_du = torch.autograd.grad(outputs=internal_y, inputs=internal_data_, grad_outputs=internal_u_grad_out, create_graph=True)[0]\n",
    "        internal_dv = torch.autograd.grad(outputs=internal_y, inputs=internal_data_, grad_outputs=internal_v_grad_out, create_graph=True)[0]\n",
    "\n",
    "        internal_dudt = internal_du[:, 0:1]\n",
    "        internal_dudx = internal_du[:, 1:2]\n",
    "        internal_dvdt = internal_dv[:, 0:1]\n",
    "        internal_dvdx = internal_dv[:, 1:2]\n",
    "\n",
    "        internal_ddudxx = torch.autograd.grad(outputs=internal_dudx, inputs=internal_data_, grad_outputs=torch.ones_like(internal_dudx), create_graph=True)[0][:, 1:2]\n",
    "        internal_ddvdxx = torch.autograd.grad(outputs=internal_dvdx, inputs=internal_data_, grad_outputs=torch.ones_like(internal_dudx), create_graph=True)[0][:, 1:2]\n",
    "\n",
    "        uv_square = internal_y[:, 0:1] ** 2 + internal_y[:, 1:2] ** 2\n",
    "        f_real = 0.5 * internal_ddudxx - internal_dvdt + uv_square * internal_y[:, 0:1]\n",
    "        f_imag = 0.5 * internal_ddvdxx + internal_dudt + uv_square * internal_y[:, 1:2]\n",
    "\n",
    "        msef = internal_loss(f_real) + internal_loss(f_imag)\n",
    "\n",
    "        # 总共误差\n",
    "        total_mse = mse0 + mseb + msef\n",
    "\n",
    "        # 清空梯度+反向传播\n",
    "        optimizer.zero_grad()\n",
    "        total_mse.backward()\n",
    "\n",
    "        return total_mse\n",
    "\n",
    "    writer = SummaryWriter(\"PINN_log_2layers\")\n",
    "    #for epoch in range(2000):\n",
    "    #    if epoch % 10 == 0 :\n",
    "    #        print(\"Epoch: {}\".format(epoch))\n",
    "    #    writer.add_scalar(\"train_%d\" % N, optimizer.step(closure).item(), epoch)\n",
    "\n",
    "    #writer.close()\n",
    "    \n",
    "    exact_data = loadmat(\"NLS.mat\")\n",
    "    idx = bisect.bisect_right(exact_data['tt'][0], 1.00)\n",
    "    t = exact_data['tt'][0][idx]\n",
    "    x = exact_data['uu'][:, idx]\n",
    "    x_axis = exact_data['x'][0]\n",
    "\n",
    "    pinn.train(False)\n",
    "\n",
    "    for epoch in range(2000):\n",
    "        if epoch % 10 == 0 :\n",
    "            pinn.train(False)\n",
    "            print(\"Epoch: {}, begin evaluation.\".format(epoch))\n",
    "            with torch.no_grad():\n",
    "                test_data = torch.full((len(x), 2), t)\n",
    "                test_data[:, 1:2] = torch.tensor(exact_data['x'].T)\n",
    "                test_data = test_data.cuda()\n",
    "                result = pinn(test_data).cpu()\n",
    "                real_part = np.asarray(result[:, 0])\n",
    "                imag_part = np.asarray(result[:, 1])\n",
    "                ext_real, ext_imag = x.real, x.imag\n",
    "                err = ((np.abs(real_part - ext_real)**2).sum()+ (np.abs(imag_part - ext_imag)**2).sum()) / len(x_axis)\n",
    "                writer.add_scalar(\"L2 error %d\" % N, err, epoch)\n",
    "            pinn.train()    \n",
    "        writer.add_scalar(\"train %d\" % N, optimizer.step(closure).item(), epoch)\n",
    "    print(err)\n",
    "    err_all.append(err)\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
